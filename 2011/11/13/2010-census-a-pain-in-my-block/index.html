<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" dir="ltr" lang="en-US">

<head profile="http://gmpg.org/xfn/11">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<title>

2010 Census: A pain in my block   | Eric van Zanten &#8211; Statically</title>

<link rel="stylesheet" href="http://www.static-eric.com/wp-content/themes/tabula-rosa/style.css" type="text/css" media="screen" />


<link rel="alternate" type="application/rss+xml" title="Eric van Zanten - Statically &raquo; Feed" href="http://www.static-eric.com/feed/" />
<link rel="alternate" type="application/rss+xml" title="Eric van Zanten - Statically &raquo; Comments Feed" href="http://www.static-eric.com/comments/feed/" />
<link rel="alternate" type="application/rss+xml" title="Eric van Zanten - Statically &raquo; 2010 Census: A pain in my block Comments Feed" href="http://www.static-eric.com/2011/11/13/2010-census-a-pain-in-my-block/feed/" />
<link rel='stylesheet' id='fancybox_css-css'  href='http://www.static-eric.com/wp-content/themes/tabula-rosa/js/fancybox/jquery.fancybox-1.3.4.css?ver=3.2.1' type='text/css' media='screen' />
<script type='text/javascript' src='http://www.static-eric.com/wp-includes/js/l10n.js?ver=20101110'></script>
<script type='text/javascript' src='http://www.static-eric.com/wp-includes/js/jquery/jquery.js?ver=1.6.1'></script>
<script type='text/javascript' src='http://www.static-eric.com/wp-includes/js/comment-reply.js?ver=20090102'></script>

 
<link rel='index' title='Eric van Zanten &#8211; Statically' href='http://www.static-eric.com/' />
<link rel='start' title='OMG FREE HOSTING: An homage to Harper Reed' href='http://www.static-eric.com/2011/10/22/omg-free-hosting-an-homage-to-harper-reed/' />
<link rel='prev' title='Mapping tools 101: A few things I&#8217;ve picked up' href='http://www.static-eric.com/2011/10/29/mapping-tools-101-a-few-things-ive-picked-up/' />
<meta name="generator" content="WordPress 3.2.1 - Realstatic 0.31" />
<link rel='canonical' href='http://www.static-eric.com/2011/11/13/2010-census-a-pain-in-my-block/' />
<link rel='shortlink' href='http://www.static-eric.com/?p=108/' />
	<style type="text/css">.recentcomments a{display:inline !important;padding:0 !important;margin:0 !important;}</style>
<meta id="syntaxhighlighteranchor" name="syntaxhighlighter-version" content="3.1.3" />

<!-- BEGIN Typekit Fonts for WordPress -->
<script type="text/javascript" src="http://use.typekit.com/sok4ukf.js"></script>
<script type="text/javascript">try{Typekit.load();}catch(e){}</script><!-- END Typekit Fonts for WordPress -->

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-26502031-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
</head>
<body class="single single-post postid-108 single-format-standard">
		
	<div id="header">
		<div id="header-wrapper">
		<h1 id="blog-title"><a href="http://www.static-eric.com/" title="Home">Eric van Zanten &#8211; Statically</a></h1>       
        <h2 id="blog-description"></h2>
        
        <!-- Design Note: Add breadcrumbs here at the end of this logic -->
        			<h2 class="breadcrumb"><a href="http://www.static-eric.com/">Home</a> - 
									<a href="http://www.static-eric.com/category/code/" title="Code">Code</a> - <a href="http://www.static-eric.com/category/how-tos/" title="How-Tos">How-Tos</a> - 2010 Census: A pain in my block				</h2>
					</h2>
		</div>
	</div>

<div id="wrapper">
	<div id="left-col">
			<div id="menu">
		<ul>
						<li class="page_item"><a href="http://www.static-eric.com/">Home</a></li>
						<li class="page_item page-item-10"><a href="http://www.static-eric.com/about-this-site/" title="About this site">About this site</a></li>
		</ul>
	</div>


		<div id="sidebar">
        	<div id="feed-container">
        		<p><a href="http://feeds.feedburner.com/static-eric" id="feed_link">Subscribe to the RSS Feed</a></p>
        	</div>

						
			<div class="widget static-widget">
				<h3 class="widgettitle">Archives</h3>
				<ul>
						<li><a href='http://www.static-eric.com/2011/11/' title='November 2011'>November 2011</a></li>
	<li><a href='http://www.static-eric.com/2011/10/' title='October 2011'>October 2011</a></li>
				</ul>
			</div>
			
			<div class="widget static-widget">
				<h3 class="widgettitle">Categories</h3>
				<ul>
						<li class="cat-item cat-item-3"><a href="http://www.static-eric.com/category/code/" title="View all posts filed under Code">Code</a>
</li>
	<li class="cat-item cat-item-4"><a href="http://www.static-eric.com/category/how-tos/" title="View all posts filed under How-Tos">How-Tos</a>
</li>
	<li class="cat-item cat-item-10"><a href="http://www.static-eric.com/category/maps/" title="View all posts filed under Maps">Maps</a>
</li>
				</ul>
			</div>
			<div class="widget static-widget">
				<h3 class="widgettitle">Search</h3>
                <form id="searchform">
                <div><input type="text" name="s" id="s" /><input type="button" id="searchsubmit" value="Search" /></div>
                </form>
			</div>
			<div id="search-results"></div>
				</div>
	</div>

	<div id="right-col">
					<div id="post-108" class="post-108 post type-post status-publish format-standard hentry category-code category-how-tos tag-bahais tag-census tag-maps tag-python">
						<h1 class="posttitle">2010 Census: A pain in my block</h1>
			<div class="post-author">written by: Eric</div>
	
			<div class="entry">
				<p>I&#8217;ve written about my very limited exploits in exploring and leveraging 2010 census data in the past but this weekend I finally got back around to doing something about it. What I ended up with is looking like a pretty useful tool for anyone looking at projecting census data onto arbitrary geographies.</p>
<p><strong>A quick recap</strong><br />
For those who didn&#8217;t read the first <a href="http://www.static-eric.com/2011/10/23/2010-census-leveraging-whats-already-been-done/" title="2010 Census: Leveraging what’s already been done" target="_blank">couple</a> <a href="http://www.static-eric.com/2011/10/24/2010-census-getting-setup/" title="2010 Census: Getting setup" target="_blank">posts</a> I wrote about the reasoning behind why I&#8217;m going through all this trouble in the first place, here&#8217;s the story so far: </p>
<p>I work for the <a href="http://www.bahai.us" title="Baha'i Faith" target="_blank">Bahá&#8217;í Faith</a>. The administration of Bahá&#8217;í communities across the continental United States is broken down into what we call Bahá&#8217;í Localities. These can sometimes be mapped one-to-one onto an existing geography, such as a municipal boundary or a county but often times are combinations or subdivisions of those areas. Which makes the task of projecting census data onto them somewhat tricky. After I wrote about getting the census.ire.org Django project setup on my local VM, I got a Twitter shout out from <a href="http://blog.germuska.com" title="Joe Germuska" target="_blank">Joe Germuska</a> over at the <a href="http://blog.apps.chicagotribune.com/" title="Chicago Tribune News Apps Blog" target="_blank">Chicago Tribune</a> suggesting that I take a look at trying to build my shapes out of the basic kernel of all census shapes: the block. So, in case the title of this post doesn&#8217;t give that away, that&#8217;s what I did.</p>
<p><strong>Re-purposing guts of the IRE app</strong><br />
Once I got the <a href="https://github.com/ireapps/census" title="IRE census project on Github" target="_blank">census.ire.org project</a> setup I kinda sat back at said to myself, &#8220;uh, OK, now what&#8230;&#8221;. My first approach was actually to forget about all the juicy goodness in there and try to just get what I needed from the API that they offer. Problem is, block level data is not available through the API (which I suppose is understandable given that there are like, 8,000,000 census blocks in the U.S.).  </p>
<p>Since no one else had the data, it was starting to look like I would have to build it myself (*gulp*). In reading the docs for the IRE Django app, the parts that intrigued me the most were the parts that actually fetched census data and loaded it someplace. The someplace, in their case, was a MongoDB database which, at the end of the day, got dumped out and turned into flat JSONP files which were then uploaded to an S3 bucket so that schmoes like me could access it through the API. Problem with that, at least for me, was that I needed some way of comparing my arbitrary shapes with the census block shapes. What I needed, in a nutshell, was a <a href="http://postgis.refractions.net/" title="PostGIS" target="_blank">PostGIS</a> database with both my arbitrary shapes and the census blocks. Luck for me, <a href="http://www.static-eric.com/2011/10/29/mapping-tools-101-a-few-things-ive-picked-up/" title="Mapping tools 101: A few things I’ve picked up" target="_blank">I&#8217;ve done that before</a>. </p>
<p>So, what it came down to for me was to basically take what they were doing, rip out the MongoDB parts, put in PostGIS parts, and run some spatial lookups. Easy, right? Well, thanks to the work that was already done, yeah. But really, really boring.</p>
<p><strong>Before the boring part, the code</strong><br />
OK, now we&#8217;ll get into the meaty part where I show you what I did. My basic approach, like the IRE app, was to write a series of scripts which actually executed the various steps in the process. The real brains of what&#8217;s going on is directly cribbed from the IRE app so I&#8217;d literally be nowhere without them. If you&#8217;re interested in seeing what they did before going any further, the hub round which everything else revolves is called batch_sf.sh and lives <a href="https://github.com/ireapps/census/tree/master/dataprocessing" title="IRE Census app on Github" target="_blank">here</a>.</p>
<p>The basic steps I came up with were slightly different than the ones that IRE uses because of a few things: all I wanted was block level data, I needed to know what area on the surface of the Earth the census data related to, and I didn&#8217;t need to get all the census tables (I cherry picked 14 that seemed to be what I was after). The steps I followed, in order, are:</p>
<ul>
<li>Load the block level geospatial data into a PostGIS database</li>
<li>Fetch the census data, generate the table headers and save it as CSV</li>
<li>Create a cross reference table that facilitates a relation between the GIS data and the census data</li>
<li>Load the block level census data into already prepared Django models for the 14 tables that I wanted</li>
<li>Finally, make the spatial relations between my arbitrary geographies and census blocks</li>
</ul>
<p>One word of caution before doing any of this stuff: working with block level data takes a huge amount of patience. When I got my batch script working, I ran it against Connecticut and it took 7 hours to complete. And that&#8217;s one of the small states with only 67,000+ census blocks. Illinois has something like 450,000+ census blocks so the scale here gets pretty astronomical pretty fast. When I get the final wrinkles ironed out, the next phase will probably involve setting this stuff up on a cloud server, just letting it crank and then coming up with a way of serializing the output into something that I can use without ever having to run this stuff again until the 2020 census.</p>
<p><strong>Load GIS data</strong><br />
This was actually remarkably simple thanks to the <a href="https://docs.djangoproject.com/en/1.3/ref/contrib/gis/layermapping/" title="GeoDjango LayerMapping" target="_blank">GeoDjango LayerMapping tool</a>. All it took was getting the data from <a href="http://www2.census.gov/geo/tiger/TIGER2010/TABBLOCK/2010/" title="Block level GIS data" target="_blank">here</a> and stuffing it into a Django model. Here&#8217;s the model I went with:</p>
<pre class="brush: python; title: ; notranslate" title="">
class CensusBlock(models.Model):
    locality = models.ForeignKey(Locality, null=True)
    xref = models.ForeignKey(XRef, null=True)
    state_fips = models.CharField(max_length=2)
    county_fips = models.CharField(max_length=3)
    tract_code = models.CharField(max_length=6)
    block_number = models.CharField(max_length=4)
    geo_id = models.CharField(max_length=15)
    name = models.CharField(max_length=10)
    feat_code = models.CharField(max_length=5)
    land_area = models.IntegerField()
    water_area = models.IntegerField()
    internal_lat = models.CharField(max_length=11)
    internal_lon = models.CharField(max_length=12)
    mpoly = models.MultiPolygonField('Block area', srid=4326)
    objects = models.GeoManager()

    def __unicode__(self):
        return u'%s, (%s)' % (self.name, self.geo_id)
</pre>
<p>The <code>locality</code> field is a <code>ForeignKey</code> to the model where I store the Bahá&#8217;í localities (my arbitrary geographies). The <code>xref</code> field is a ForeignKey to a cross reference table that, at least while it&#8217;s loading, gives us the ability to relate a place on the surface of the earth to the number of people that live there. Other than that, it&#8217;s pretty much a one-to-one mapping of the GIS data that you get from the Census Bureau. Here&#8217;s my LayerMapping script:</p>
<pre class="brush: python; title: ; notranslate" title="">
#!/bin/env python

# All this stuff is just the normal dance you do to get the environment setup for Django to work
import sys
import site
import os
vepath = '/home/wdo/sites/my.bahai.us/lib/python2.6/site-packages'
prev_sys_path = list(sys.path)

site.addsitedir(vepath)
sys.path.append('/home/wdo/sites/my.bahai.us/checkouts/mybahai')
sys.path.append('/home/wdo/sites/my.bahai.us/checkouts')

new_sys_path = [p for p in sys.path if p not in prev_sys_path]
for item in new_sys_path:
    sys.path.remove(item)
sys.path[:0] = new_sys_path

os.environ['DJANGO_SETTINGS_MODULE'] = 'mybahai.settings'

from psycopg2 import IntegrityError

from django.contrib.gis.utils import mapping, LayerMapping, add_postgis_srs
from mybahai.census.models import CensusBlock
from django.conf import settings

if len(sys.argv) &lt; 2:
    sys.exit('You must provide the state name of the block data you want to load an argument to this script.')

STATE = sys.argv[1]

try:
    add_postgis_srs(900913)
except IntegrityError:
    print &quot;The Google Spherical Mercator projection, or a projection with srid 900913, already exists, skipping insert&quot;

census_shp = os.path.join(settings.PROJECT_PATH,'census/scripts/data/tl_2010_' + STATE + '_tabblock10/tl_2010_' + STATE + '_tabblock10.shp')

census_mapping = {
    'state_fips': 'STATEFP10',
    'county_fips': 'COUNTYFP10',
    'tract_code': 'TRACTCE10',
    'block_number': 'BLOCKCE10',
    'geo_id': 'GEOID10',
    'name': 'NAME10',
    'feat_code': 'MTFCC10',
    'land_area': 'ALAND10',
    'water_area': 'AWATER10',
    'internal_lat': 'INTPTLAT10',
    'internal_lon': 'INTPTLON10',
    'mpoly': 'MULTIPOLYGON',

}

census_layer = LayerMapping(CensusBlock,
                      census_shp,
                      census_mapping,
                      transform=False,
                      encoding='iso-8859-1')

census_layer.save(verbose=False, strict=True, progress=True)
</pre>
<p>As I mentioned above, this is something that can take an insane amount of time to complete. If you&#8217;re having trouble getting it to finish the whole job, the LayerMapping tool does support passing a <code>fid_range</code> keyword argument into the <code>.save()</code> method with a tuple containing the indexes of the first and last features you want to load. That gives you a way of resuming should something get frozen or die on you. On a test run, I was able to load all 450,000+ shapes for the state of Illinois into my Ubuntu VMs with relatively limited resources (512MB RAM for app server and 1024MB RAM for db server) on my Intel i5 MacBook Pro. It finished. Eventually. It helps if you don&#8217;t watch.</p>
<p><strong>Fetching census data</strong><br />
This part is basically grabs the raw data from the Census Bureau, does some basic cleanup and generates the table headers (using <a href="https://github.com/ireapps/census/blob/master/dataprocessing/make_sf_data_2010_headers.py" title="Making 2010 census table headers" target="_blank">this script</a> from IRE) so that the next step is easier. I pretty much directly ripped this part off from <a href="https://github.com/ireapps/census/blob/master/dataprocessing/fetch_sf_data_2010.sh" title="Fetch 2010 data script" target="_blank">this script</a> from within the IRE project. Hey, they told me to <a href="http://blog.apps.chicagotribune.com/2011/10/19/steal-this-code-presentation-to-hackshackers-opengovchicago/" title="Steal this code: News Apps Blog" target="_blank">steal it</a>. One thing I want to point out from within that file is the last line:</p>
<pre class="brush: bash; title: ; notranslate" title="">
in2csv -e &quot;latin-1&quot; -f fixed -s ${DATAPROCESSING_DIR}/census2010_geo_schema.csv ${STATE_NAME_ABBR}geo2010.sf1 &gt; ${STATE_NAME_ABBR}geo2010.csv
</pre>
<p>This leverages the ever useful <a href="https://github.com/onyxfish/csvkit" title="CSVKit on Github" target="_blank">csvkit</a> to take the census2010_geo_schema.csv file and add it as a header to the info about the actual geographic areas that are part of the raw census data you downloaded in the first part of the script. This becomes kind of the lynchpin when we get to the part where we&#8217;re loading the census tables into Django models.  </p>
<p><strong>Make cross reference table</strong><br />
The Census Bureau provides the census data in what I consider to be relatively cryptic form. I suppose it&#8217;s all in the interest of making it portable and platform agnostic but for me it was somewhat of a headache to make heads or tails of what was going on there. Again, if it weren&#8217;t for the work put in on the IRE project, I would be nowhere.</p>
<p>The first part of the headache was trying to relate the geospatial data that we&#8217;ve already loaded to the census tables that we&#8217;re about to load so that when you query a place, you know how many people live there. The way this was accomplished by the IRE project was by building sort of a throw away cross reference relation that both the data about a place and the census data about that place have in common. Which is trickier than it sounds for reasons that are totally unknown to me. Since MongoDB is a non-relational database, the process that the IRE project had to go through to make the relation involved making a key that was stored when you loaded the info about a place and then could refer to later when loading the census data about that that place. My approach was to build a table that each geography would have a ForeignKey to and then looking up that geography using that relation when I loaded the census data. It has pretty much the same effect as the IRE approach only it&#8217;s relational rather than non-relational. Anyways, here&#8217;s the code I used to make the cross reference table:</p>
<pre class="brush: python; title: ; notranslate" title="">
#!/usr/bin/env python

import sys
import site
import os
import json

from csvkit.unicsv import UnicodeCSVReader

import config
import utils

... Normal Django environment setup goes here ...

from mybahai.census.models import CensusBlock, XRef

if len(sys.argv) &lt; 2:
    sys.exit('You must provide the filename of a CSV as an argument to this script.')

FILENAME = sys.argv[1]

def make_xref(d):
    # Strip off unncessary attrs
    d.pop('CHARITER')
    d.pop('CIFSN')
    x, created = XRef.objects.get_or_create(fileid=d.pop('FILEID'), stusab=d.pop('STUSAB'), logrecno=d.pop('LOGRECNO'))
    return x

with open(FILENAME) as f:
    rows = UnicodeCSVReader(f)
    headers = rows.next()

    for row in rows:

        geography = {}
        row_dict = dict(zip(headers, row))

        if row_dict['SUMLEV'] not in config.SUMLEVS:
            continue

        # Ignore that is not for complete geographies
        if row_dict['GEOCOMP'] != config.GEOCOMP_COMPLETE:
            continue

        geography['sumlev'] = row_dict.pop('SUMLEV')
        geography['geoid'] = utils.GEOID_COMPUTERS[geography['sumlev']](row_dict)

        xref = make_xref(row_dict)
        block = CensusBlock.objects.get(geo_id=geography['geoid'])
        block.xref = xref
        block.save()
</pre>
<p>The crux of what&#8217;s going on here is that it&#8217;s taking the <code>[state abbrv]geo2010.csv</code> file that you created in step two, going through it row by row, creating a cross reference based upon the <code>FILEID</code>, (which is basically the same for all of these since we&#8217;re just using the <a href="http://www2.census.gov/census_2010/04-Summary_File_1/" title="Census Data Summary File - raw data" target="_blank">census summary file</a>) the <code>STUSAB</code> (which is a state level identifier) and the <code>LOGRECNO</code> which is basically an index number for the entry in question. We&#8217;re then associating that with a particular census block based upon it&#8217;s <code>geoid</code>. That&#8217;s basically a concatenation of the various <a href="http://en.wikipedia.org/wiki/Federal_Information_Processing_Standard" title="FIPS on Wikipedia" target="_blank">FIPS</a> codes of the areas that contain that block plus the block number. </p>
<p>One thing to note is that this script uses two external modules for some of it&#8217;s functionality <code>config</code> and <code>utils</code>. In my implementation, these are pretty much straight copies of <a href="https://github.com/ireapps/census/blob/master/dataprocessing/config.py" title="IRE dataprocessing config file" target="_blank">this</a> and <a href="https://github.com/ireapps/census/blob/master/dataprocessing/utils.py" title="IRE dataprocessing utils file" target="_blank">this</a>, respectively. I&#8217;m not using everything in there since some of it has to do with the MongoDB parts.</p>
<p>The part that makes a huge difference (and took me a fair bit of time to figure out) was to enable the block <code>SUMLEV</code> in the <code>config</code> file (this is what that <code>if row_dict['SUMLEV'] not in config.SUMLEVS</code> bit up there is all about). When you get the code from the IRE Github repo, it&#8217;s not turned on by default (which is understandable). To do that, you just need to add it to <code>SUMLEVS</code> list on line 16 of the <code>config</code> file. For good measure, I also turned all the other ones off so I wouldn&#8217;t be loading data that I wasn&#8217;t going to be using.</p>
<p><strong>Actually loading the census counts</strong><br />
Now that we&#8217;ve made it possible to cross reference the census data with the geospatial data, let&#8217;s load it up. Just so you know what we&#8217;re working with, the SF1 (Summary File 1) data that we&#8217;re loading here is broken down into 300+ tables which are divided amongst the 47 files we downloaded in step two. You can see the extensive (and rather nitpicky) nature of what that looks like in the census.ire.org app (<a href="http://census.ire.org/data/1714000.html" title="Chicago census data" target="_blank">here&#8217;s Chicago</a>). Since I&#8217;m really only after 14 of these tables, I only built models to house 14 of them. Here&#8217;s a sample (putting the whole thing here would just be silly):</p>
<pre class="brush: python; title: ; notranslate" title="">
class P1(models.Model):
    geo_id = models.CharField(max_length=15, primary_key=True)
    p001001 = models.IntegerField()

    def __unicode_(self):
        return 'Total Population'

class P3(models.Model):
    geo_id = models.CharField(max_length=15, primary_key=True)
    p003001 = models.IntegerField()
    p003002 = models.IntegerField()
    p003003 = models.IntegerField()
    p003004 = models.IntegerField()
    p003005 = models.IntegerField()
    p003006 = models.IntegerField()
    p003007 = models.IntegerField()
    p003008 = models.IntegerField()

    def __unicode_(self):
        return 'Race %s' % self.geo_id

... etc ...
</pre>
<p>The script used to load data into these is, again, based heavily upon what was already in the IRE project, just with the MongoDB parts taken out and the Django ORM/PostgreSQL/PostGIS parts put in. Here&#8217;s what that looks like:</p>
<pre class="brush: python; title: ; notranslate" title="">
#!/bin/env python
import sys
import site
import os
import json

... Normal Django environment setup ...

from mybahai.census.models import *
import sys
from csvkit.unicsv import UnicodeCSVReader
import utils
import config

if len(sys.argv) &lt; 2:
    sys.exit('You must provide the filename of a CSV as an argument to this script.')

FILENAME = sys.argv[1]

GET_CENSUS_TABLE = {
    'P1' : P1,
    'P3': P3,
... bunch more keys related to Django models for census tables ...
}

with open(FILENAME) as f:
    rows = UnicodeCSVReader(f)
    headers = rows.next()

    for row in rows:
        row_dict = dict(zip(headers, row))

        try:
            x = XRef.objects.get(fileid=row_dict['FILEID'], stusab=row_dict['STUSAB'], logrecno=row_dict['LOGRECNO'])
        except XRef.DoesNotExist:
            continue
        block = CensusBlock.objects.get(xref=x)

        geo_id = block.geo_id

        tables = {}
        for k, v in row_dict.items():
            t = utils.parse_table_from_key(k)
            if t:
                if t not in tables:
                    tables[t] = {}

                tables[t][k] = v
        for k, v in tables.items():
            if k not in GET_CENSUS_TABLE.keys():
                continue
            m = GET_CENSUS_TABLE[k]
            v = dict((k.lower(), v) for k,v in v.iteritems())
            v['geo_id'] = geo_id
            o = m(**v)
            o.save()
</pre>
<p>Quick rundown of the action here: we&#8217;re getting a census table file (one of the 47 created in step 2) as a command line argument, and associating each row with a <code>CensusBlock</code> object based upon that ever handy cross reference table that we created earlier. The <code>utils.parse_table_from_key(k)</code> part is, again, referencing a function from the <code>utils</code> module that uses a regex to parse which census table the row being looked at contains data from based upon the pattern that is present in the row. Since I&#8217;m only interested in 14 of the tables, I&#8217;m only actually loading the data that is from those tables (hence the <code>if k not in GET_CENSUS_TABLE.keys():</code> part. After that, it&#8217;s just passing the geo_id and the table values into the Django model (which is looked up in the <code>GET_CENSUS_TABLE</code> dict) as keyword arguments. By the way, that&#8217;s my new favorite Python shortcut: <code>o = m(**v)</code>.</p>
<p><strong>The final relation</strong><br />
The final step here is to relate my arbitrary geographies with the census blocks they contain. I chose to do this by creating a <code>ForeignKey</code> from the <code>CensusBlock</code> object to the <code>Locality</code> object which contains it. I&#8217;m still tweaking the actual queries that I&#8217;m going to run in this stage but, for the purposes of a proof of concept, it&#8217;s pretty solid. Here&#8217;s my script for this last stage:</p>
<pre class="brush: python; title: ; notranslate" title="">
#!/bin/env python
import sys
import site
import os
import json

from csvkit.unicsv import UnicodeCSVReader

import config
import utils

... LA LA LA Django env setup LA LA LA ...

from mybahai.census.models import *
from mybahai.natgeo.models import Locality

if len(sys.argv) &lt; 2:
    sys.exit('You must provide a state abbreviation as an argument for this script.')

STATE = sys.argv[1]

locs = Locality.objects.filter(locality_state__state_abrv=STATE.upper())
for loc in locs:
    first_pass = CensusBlock.objects.filter(mpoly__coveredby=loc.mpoly)
    total_pop = 0
    for block in first_pass:
        block.locality = loc
        block.save()
        p1 = P1.objects.filter(geo_id=block.geo_id)
        total_pop += p1[0].p001001
    second_pass = CensusBlock.objects.filter(mpoly__overlaps=loc.mpoly)
    for block in second_pass:
        if not block.locality:
            block.locality = loc
            block.save()
            p1 = P1.objects.filter(geo_id=block.geo_id)
            total_pop += p1[0].p001001
    third_pass = CensusBlock.objects.filter(mpoly__bboverlaps=loc.mpoly)
    for block in third_pass:
        if not block.locality:
            block.locality = loc
            block.save()
            p1 = P1.objects.filter(geo_id=block.geo_id)
            total_pop += p1[0].p001001
    loc.locality_census_pop = total_pop
    loc.save()
    print 'Saved %s' % loc.locality_name
</pre>
<p>I&#8217;m actually trying to catch the census blocks associated with a particular area in three, ever widening, passes because the first time I tried this, just using the <code>CensusBlock.objects.filter(mpoly__coveredby=loc.mpoly)</code> filter, I ended up with a bunch of <code>CensusBlock</code> objects that weren&#8217;t associated with any <code>Locality</code> objects. It&#8217;s still a little messy but, just to show you it can actually be done, here&#8217;s a screen shot showing a side-by-side comparison of what our Washington, D.C. <code>Locality</code> boundaries (which in this case correspond precisely with the actual boundaries of Washington, D.C.) look like next to all the census blocks that make it up:</p>
<p><img src="http://www.static-eric.com/wp-content/uploads/2011/11/side-by-side-dc-1024x687.jpg" alt="" title="side-by-side-dc" width="720" height="483" class="aligncenter size-large wp-image-126" /></p>
<p><strong>Wrapping it up</strong><br />
After I had my 5 scripts together, I made another script that basically takes a state name as command line argument and executes all the other scripts in order. It also handles downloading and unpacking the data:</p>
<pre class="brush: bash; title: ; notranslate" title="">
#!/bin/bash

if [ $# \&lt; 1 ]
then
    echo &quot;You must specify exactly one argument: the proper-case name of a state '0.Batch.sh Delaware'.&quot;
    exit
fi

STATE_NAME=&quot;${@:1:1}&quot;
STATE_NAME_SPACE_FIXED=`echo &quot;${STATE_NAME}&quot; | tr '[ ]' '[_]'`
STATE_NAME_LOWER=`echo &quot;${STATE_NAME}&quot; | tr '[A-Z ]' '[a-z_]'`
STATE_NAME_ABBR=`python get_state_abbr.py &quot;${STATE_NAME}&quot;` || exit $?
STATE_FIPS=`python get_state_fips.py &quot;${STATE_NAME}&quot;` || exit $?

echo Begin $STATE_NAME at `date`

echo 'Fetching Geo Data'
mkdir data/tl_2010_${STATE_FIPS}_tabblock10
wget -O data/tl_2010_${STATE_FIPS}_tabblock10/tl_2010_${STATE_FIPS}_tabblock10.zip http://www2.census.gov/geo/tiger/TIGER2010/TABBLOCK/2010/tl_2010_${STATE_FIPS}_tabblock10.zip
unzip data/tl_2010_${STATE_FIPS}_tabblock10/tl_2010_${STATE_FIPS}_tabblock10.zip -d data/tl_2010_${STATE_FIPS}_tabblock10/

echo 'Loading Geo Data'
python 1.LoadBlockGeo.py ${STATE_FIPS} || exit $?

echo 'Fetching Census Data'
./2.FetchCensusData.sh &quot;$STATE_NAME_SPACE_FIXED&quot; &quot;$STATE_NAME_LOWER&quot; &quot;$STATE_NAME_ABBR&quot;

echo 'Loading Cross reference table'
python 3.LoadXref.py data/${STATE_NAME_ABBR}geo2010.csv || exit $?

echo 'Loading 2010 data'
# Only loading certain csvs cause I'm only building some census tables
# for i in {1..47} to load all data
for i in 1 3 4 5 6 44 47
do
    python 4.LoadBlockData.py data/sf_data_2010_${STATE_NAME_LOWER}_$i.csv || exit $?
done

echo 'Relating Blocks to Localities'

python 5.MakeLocalityRel.py ${STATE_NAME_ABBR} || exit $?

echo Complete $STATE_NAME at `date`
</pre>
<p>So, really all you have to do is execute that and wait. And wait. It takes a really long time. Maybe go take in a movie. Or a movie marathon. Watch all 5 seasons of <a href="http://en.wikipedia.org/wiki/The_wire" title="The Wire" target="_blank">The Wire</a>. You get the idea&#8230;</p>
<p><strong>In all practicality&#8230;</strong><br />
Getting this far was relatively simple, given the amount of work that was already done for me by the wonderful IRE project. The next stage is going to be kind of where the rubber hits the road in terms of usability. I don&#8217;t really want to have to run through this process on every state more than once so I&#8217;m thinking I&#8217;ll probably just serialize the parts I need and store them in an S3 bucket where I can grab it when I need it. But that&#8217;s a project for later&#8230; </p>
								
			</div>
	
			<div class="post-metadata alt">
				<p><strong>Date:</strong> <a href="http://www.static-eric.com/2011/11/13/2010-census-a-pain-in-my-block/" rel="bookmark" title="Permanent Link to 2010 Census: A pain in my block">November 13th, 2011</a> </p>
				<p><strong>Category:</strong> <a href="http://www.static-eric.com/category/code/" title="View all posts in Code" rel="category tag">Code</a>, <a href="http://www.static-eric.com/category/how-tos/" title="View all posts in How-Tos" rel="category tag">How-Tos</a></p>
				<p><strong>Tags:</strong> <a href="http://www.static-eric.com/tag/bahais/" rel="tag">Baha'is</a>, <a href="http://www.static-eric.com/tag/census/" rel="tag">Census</a>, <a href="http://www.static-eric.com/tag/maps/" rel="tag">Maps</a>, <a href="http://www.static-eric.com/tag/python/" rel="tag">Python</a></p>				<p><strong>Comments/Trackbacks:</strong>
								<a href="#respond">Comments</a>, or <a href="http://www.static-eric.com/2011/11/13/2010-census-a-pain-in-my-block/trackback/" rel="trackback">trackback</a> allowed.</p>
	
								</p>
			</div>
	
<div id="disqus_thread">
    </div>

<script type="text/javascript">
/* <![CDATA[ */
    var disqus_url = 'http://www.static-eric.com/2011/11/13/2010-census-a-pain-in-my-block/';
    var disqus_identifier = '108 http://www.static-eric.com/?p=108';
    var disqus_container_id = 'disqus_thread';
    var disqus_domain = 'disqus.com';
    var disqus_shortname = 'static-eric';
    var disqus_title = "2010 Census: A pain in my block";
        var disqus_config = function () {
        var config = this; // Access to the config object

        /* 
           All currently supported events:
            * preData — fires just before we request for initial data
            * preInit - fires after we get initial data but before we load any dependencies
            * onInit  - fires when all dependencies are resolved but before dtpl template is rendered
            * afterRender - fires when template is rendered but before we show it
            * onReady - everything is done
         */

        config.callbacks.preData.push(function() {
            // clear out the container (its filled for SEO/legacy purposes)
            document.getElementById(disqus_container_id).innerHTML = '';
        });
                config.callbacks.onReady.push(function() {
            // sync comments in the background so we don't block the page
            DISQUS.request.get('?cf_action=sync_comments&post_id=108');
        });
                    };
    var facebookXdReceiverPath = 'http://www.static-eric.com/wp-content/plugins/disqus-comment-system/xd_receiver.htm';
/* ]]> */
</script>

<script type="text/javascript">
/* <![CDATA[ */
    var DsqLocal = {
        'trackbacks': [
        ],
        'trackback_url': "http:\/\/static\/wordpress\/2011\/11\/13\/2010-census-a-pain-in-my-block\/trackback\/"    };
/* ]]> */
</script>

<script type="text/javascript">
/* <![CDATA[ */
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = 'http://' + disqus_shortname + '.' + disqus_domain + '/embed.js?pname=wordpress&pver=2.67';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
/* ]]> */
</script>
	</div>		
</div>

	<div id="footer">
		<p>&copy; 2010 Eric van Zanten &#8211; Statically | Powered by <a href="http://www.sorben.org/really-static/">really static WordPress</a> | Theme: <a href="http://leonewball.com/portfolio/tabula-rosa/">tabula rosa</a> | <a href="http://www.static-eric.com/feed/">RSS Feed</a></p>
	</div>

<script type='text/javascript' src='http://www.static-eric.com/wp-content/themes/tabula-rosa/js/menuslide.js?ver=1.0'></script>
<script type='text/javascript' src='http://www.static-eric.com/wp-content/themes/tabula-rosa/js/togglewidgets.js?ver=1.0'></script>
<script type='text/javascript' src='http://www.static-eric.com/wp-content/themes/tabula-rosa/js/fancybox/jquery.fancybox-1.3.4.js?ver=1.3.4'></script>
<script type='text/javascript' src='http://www.static-eric.com/wp-content/themes/tabula-rosa/js/fancybox_settings.js?ver=1.0'></script>
<script type='text/javascript' src='http://www.static-eric.com/wp-content/plugins/syntaxhighlighter/syntaxhighlighter3/scripts/shCore.js?ver=3.0.83c'></script>
<script type='text/javascript' src='http://www.static-eric.com/wp-content/plugins/syntaxhighlighter/syntaxhighlighter3/scripts/shBrushPython.js?ver=3.0.83c'></script>
<script type='text/javascript' src='http://www.static-eric.com/wp-content/plugins/syntaxhighlighter/syntaxhighlighter3/scripts/shBrushBash.js?ver=3.0.83c'></script>
<script type='text/javascript'>
	(function(){
		var corecss = document.createElement('link');
		var themecss = document.createElement('link');
		var corecssurl = "http://www.static-eric.com/wp-content/plugins/syntaxhighlighter/syntaxhighlighter3/styles/shCore.css?ver=3.0.83c";
		if ( corecss.setAttribute ) {
				corecss.setAttribute( "rel", "stylesheet" );
				corecss.setAttribute( "type", "text/css" );
				corecss.setAttribute( "href", corecssurl );
		} else {
				corecss.rel = "stylesheet";
				corecss.href = corecssurl;
		}
		document.getElementsByTagName("head")[0].insertBefore( corecss, document.getElementById("syntaxhighlighteranchor") );
		var themecssurl = "http://www.static-eric.com/wp-content/plugins/syntaxhighlighter/syntaxhighlighter3/styles/shThemeDefault.css?ver=3.0.83c";
		if ( themecss.setAttribute ) {
				themecss.setAttribute( "rel", "stylesheet" );
				themecss.setAttribute( "type", "text/css" );
				themecss.setAttribute( "href", themecssurl );
		} else {
				themecss.rel = "stylesheet";
				themecss.href = themecssurl;
		}
		//document.getElementById("syntaxhighlighteranchor").appendChild(themecss);
		document.getElementsByTagName("head")[0].insertBefore( themecss, document.getElementById("syntaxhighlighteranchor") );
	})();
	SyntaxHighlighter.config.strings.expandSource = '+ expand source';
	SyntaxHighlighter.config.strings.help = '?';
	SyntaxHighlighter.config.strings.alert = 'SyntaxHighlighter\n\n';
	SyntaxHighlighter.config.strings.noBrush = 'Can\'t find brush for: ';
	SyntaxHighlighter.config.strings.brushNotHtmlScript = 'Brush wasn\'t configured for html-script option: ';
	SyntaxHighlighter.defaults['pad-line-numbers'] = false;
	SyntaxHighlighter.defaults['toolbar'] = false;
	SyntaxHighlighter.all();
</script>
<script type="text/javascript" src="http://www.static-eric.com/wp-content/themes/tabula-rosa/js/search.js"></script>
</body>
</html>
